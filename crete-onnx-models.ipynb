{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d912996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "# import torch.nn as nn \n",
    "import time\n",
    "import math\n",
    "# import torch.nn.functional as F\n",
    "from net import *\n",
    "from utils import *\n",
    "from tracker import *\n",
    "import onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0678e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone_m = Inception3_M()\n",
    "backbone_m.update_params()\n",
    "backbone_q = Inception3_Q()\n",
    "backbone_q.update_params()\n",
    "neck_m = AdjustLayer()\n",
    "neck_m.update_params()\n",
    "neck_q = AdjustLayer()\n",
    "neck_q.update_params()\n",
    "head = STMHead()\n",
    "head.update_params()\n",
    "\n",
    "model = STMTrack(backbone_m, backbone_q, neck_m, neck_q, head)\n",
    "# model.update_params()\n",
    "\n",
    "# Convert BatchNorm to SyncBatchNorm \n",
    "# task_model = convert_model(task_model)\n",
    "model_file = \"new-epoch-19.pkl\"\n",
    "\n",
    "# model_file = \"epoch-19.pkl\"\n",
    "model_state_dict = torch.load(model_file,\n",
    "                        map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# model.load_state_dict(model_state_dict['model_state_dict'])\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ecbd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basemodel_Q(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Basemodel_Q, self).__init__()\n",
    "        self.backbone_q = model.basemodel_q\n",
    "        self.neck_q = model.neck_q\n",
    "    def forward(self, search_img):\n",
    "        fq = self.backbone_q(search_img)\n",
    "        fq = self.neck_q(fq)\n",
    "        return fq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b8fd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Basemodel_Q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ffeff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = \"backbone_q.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2539c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,3,289,289).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "torch.onnx.export(net, input, ONNX_FILE_PATH, input_names=[\"search_img\"], output_names=[\"fq\"], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30f2d0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "025ff223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 25, 25])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a76eeb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memorize(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Memorize, self).__init__()\n",
    "        self.backbone_m = model.basemodel_m\n",
    "        self.neck_m = model.neck_m\n",
    "    def forward(self, im_crop, fg_bg_label_map):\n",
    "        fm = self.backbone_m(im_crop, fg_bg_label_map)\n",
    "        fm = self.neck_m(fm)\n",
    "        fm = fm.permute(1, 0, 2, 3).unsqueeze(0).contiguous()  # B, C, T, H, W\n",
    "        return fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bc3dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Memorize()#(model.basemodel_m,model.neck_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e155d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.ones(1,3,289,289).cuda()\n",
    "fg_bg = torch.ones(1,1,289,289).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "fm = net(input,fg_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76de01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_FILE_PATH = \"memorize.onnx\"\n",
    "input = torch.randn(1,3,289,289).cuda()\n",
    "fg_bg = torch.randn(1,1,289,289).cuda()\n",
    "net.eval()\n",
    "net.cuda()\n",
    "torch.onnx.export(net, (input,fg_bg), ONNX_FILE_PATH, input_names=[\"img\",\"fg_bg_label_map\"], output_names=[\"fm\"], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ddf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = net(input,fg_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66702c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(xy_ctr, offsets):\n",
    "    offsets = offsets.permute(0, 2, 3, 1)  # (B, H, W, C), C=4\n",
    "    offsets = offsets.reshape(offsets.shape[0], -1, 4)\n",
    "    xy0 = (xy_ctr[:, :, :] - offsets[:, :, :2])\n",
    "    xy1 = (xy_ctr[:, :, :] + offsets[:, :, 2:])\n",
    "    bboxes_pred = torch.cat([xy0, xy1], 2)\n",
    "\n",
    "    return bboxes_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8fe0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "hps = dict(\n",
    "        total_stride=8,\n",
    "        score_size=25,\n",
    "        score_offset=-1,\n",
    "        test_lr=0.95,\n",
    "        penalty_k=0.04,\n",
    "        window_influence=0.21,\n",
    "        windowing=\"cosine\",\n",
    "        m_size=289,\n",
    "        q_size=289,\n",
    "        min_w=10,\n",
    "        min_h=10,\n",
    "        phase_memorize=\"memorize\",\n",
    "        phase_track=\"track\",\n",
    "        corr_fea_output=False,\n",
    "        num_segments=4,\n",
    "        confidence_threshold=0.6,\n",
    "        gpu_memory_threshold=-1,\n",
    "        search_area_factor=4.0,\n",
    "        visualization=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e68820f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self,head):\n",
    "        super(Head, self).__init__()\n",
    "        self.head = head\n",
    "        self.total_stride = 8\n",
    "        score_offset = (hps[\"q_size\"] - 1.0 - (hps[\"score_size\"] - 1) * hps[\"total_stride\"]) // 2.0\n",
    "        self.fm_ctr = get_xy_ctr_np(hps[\"score_size\"], score_offset, hps[\"total_stride\"])\n",
    "    def forward(self,fm,fq):\n",
    "#         q_size = 299\n",
    "#         fm = fm.permute(0, 2,1, 3, 4)\n",
    "        y = self.head.memory_read(fm, fq)\n",
    "        cls_score, ctr_score, offsets = self.head.solve(y)\n",
    "        \n",
    "        cls_score = cls_score.permute(0, 2, 3, 1)\n",
    "        cls_score = cls_score.reshape(cls_score.shape[0], -1, 1)\n",
    "\n",
    "        ctr_score = ctr_score.permute(0, 2, 3, 1)\n",
    "        ctr_score = ctr_score.reshape(ctr_score.shape[0], -1, 1)\n",
    "\n",
    "        offsets = torch.exp(self.head.si * offsets + self.head.bi) * self.total_stride\n",
    "\n",
    "        \n",
    "        fm_ctr = self.fm_ctr.to(offsets.device)\n",
    "        bbox = get_box(fm_ctr, offsets)\n",
    "        fcos_cls_score_final = cls_score\n",
    "        fcos_ctr_score_final = ctr_score\n",
    "        fcos_bbox_final = bbox\n",
    "\n",
    "        \n",
    "        fcos_cls_prob_final = torch.sigmoid(fcos_cls_score_final)\n",
    "        fcos_ctr_prob_final = torch.sigmoid(fcos_ctr_score_final)\n",
    "        # apply centerness correction\n",
    "        fcos_score_final = fcos_cls_prob_final * fcos_ctr_prob_final\n",
    "        \n",
    "        return fcos_score_final, fcos_bbox_final, fcos_cls_prob_final, fcos_ctr_prob_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9cf34910",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Head(model.head)\n",
    "net.eval()\n",
    "net.cuda()\n",
    "ONNX_FILE_PATH = \"head.onnx\"\n",
    "fm = torch.randn(1, 512, 6, 25, 25).cuda()\n",
    "fq = torch.randn(1, 512, 25, 25).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d5e6dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, (fm,fq), \n",
    "                  ONNX_FILE_PATH, input_names=[\"fm\",\"fq\"], \n",
    "                  output_names=[\"fcos_score_final\", \"fcos_bbox_final\",\n",
    "                                \"fcos_cls_prob_final\",\"fcos_ctr_prob_final\"]\n",
    "                  , export_params=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
